import { GoogleGenAI } from "@google/genai";

const getAiClient = () => {
  const apiKey = process.env.API_KEY;
  if (!apiKey) {
    console.warn("API_KEY is missing. Calls will fail.");
    return new GoogleGenAI({ apiKey: "" });
  }
  return new GoogleGenAI({ apiKey: apiKey });
};

/** è±†åŒ…/ç«å±± API Keyï¼ˆå›¾åƒç”Ÿæˆã€å¯¹è¯ï¼‰ï¼ŒVite éœ€åœ¨ .env é…ç½® VITE_DOUBAO_API_KEY */
function getDoubaoApiKey(): string {
  const env = typeof import.meta !== "undefined" ? (import.meta as any).env : {};
  return (env.VITE_DOUBAO_API_KEY || "").trim();
}

const USE_CORS_PROXY =
  typeof import.meta !== "undefined" && (import.meta as any).env?.VITE_USE_CORS_PROXY === "true";
const CORS_PROXY_PREFIX =
  (typeof import.meta !== "undefined" && (import.meta as any).env?.VITE_CORS_PROXY) || "https://corsproxy.io/?";

// CRITICAL FIX: Explicitly check for string "null" which causes "nullhttps://..."
function getFallbackCorsProxy(): string | null {
  const proxy = USE_CORS_PROXY ? CORS_PROXY_PREFIX : null;
  if (!proxy || proxy === "null" || proxy === "undefined" || proxy === "false") {
    return null;
  }
  return proxy;
}

/** ä¼˜å…ˆåŒæº /api/proxyï¼›origin ä¸º null/"null" æ—¶ç”¨ç›¸å¯¹è·¯å¾„ï¼Œé¿å…æ‹¼å‡º nullhttps://... */
export function getProxyUrl(target: string): string {
  const origin = typeof window !== "undefined" ? window.location?.origin : "";
  const base = origin && origin !== "null" ? origin : "";
  if (base) return `${base}/api/proxy?url=${encodeURIComponent(target)}`;
  const fallback = getFallbackCorsProxy();
  if (fallback && fallback !== "null" && fallback !== "undefined") return fallback + encodeURIComponent(target);
  return `/api/proxy?url=${encodeURIComponent(target)}`;
}

/**
 * Helper: Generate a fallback prompt locally if API fails.
 * Enhanced to provide richer, video-ready prompts.
 */
const generateFallbackPrompt = (
  userInput: string,
  style: string,
  viewDistance: string,
  variation: string,
  sceneFocus?: string
): string => {
  const styleKeywords: Record<string, string> = {
    'Photorealistic': 'cinematic film still, hyper-realistic, 8k resolution, ray tracing, highly detailed texture, atmospheric lighting, Arri Alexa, bokeh',
    'Cyberpunk': 'futuristic neon city, cybernetic details, high tech, night time, volumetric fog, blade runner style, vibrant neon colors',
    'Anime': 'Makoto Shinkai style, Studio Ghibli, high quality anime art, vibrant colors, detailed background, beautiful composition, 4k',
    'Watercolor': 'masterpiece watercolor painting, soft bleeding edges, artistic paper texture, dreamy atmosphere, elegant brushwork',
    'Oil Painting': 'classic oil painting on canvas, impasto brush strokes, rich colors, texture, impressionist masterpiece, dramatic lighting',
    '3D Render': 'Unreal Engine 5 render, Octane render, C4D, hyper detailed, subsurface scattering, global illumination, 3D masterpiece',
    'Pixel Art': 'high quality pixel art, 16-bit, detailed sprites, retro aesthetic, vibrant palette, game asset style',
    'Minimalist': 'clean minimalist design, flat colors, simple geometric shapes, vector art, high contrast, elegant composition'
  };

  const viewKeywords: Record<string, string> = {
    'Close-up': 'extreme close-up shot, macro details, focus on facial features and texture, shallow depth of field',
    'Wide Shot': 'wide angle establishing shot, epic scale, detailed environment, vast landscape, cinematic composition',
    'Default': 'cinematic medium shot, perfectly framed, balanced composition, movie keyframe'
  };

  const extraStyle = styleKeywords[style] || 'highly detailed, cinematic quality, masterpiece, 8k';
  const viewDesc = viewKeywords[viewDistance] || 'cinematic shot';
  const eraNote = 'consistent time period and era, no anachronism, same world and story.';
  const noText = 'no text, no words, no letters, no writing, no captions in the image.';
  const subject = (sceneFocus && sceneFocus.trim()) ? sceneFocus.trim() : userInput;
  return `(Masterpiece, top quality) ${viewDesc} of ${subject}. ${eraNote} ${variation}. ${extraStyle}, dramatic lighting, trending on ArtStation, vivid details, sharp focus. ${noText}`;
};

export type ReasoningEffort = 'minimal' | 'low' | 'medium' | 'high';

/**
 * å°†ç”¨æˆ·çš„ä¸€æ®µè¯åˆ‡åˆ†ä¸º N ä¸ªåœºæ™¯æè¿°ï¼Œç”¨äºè§†é¢‘åˆ†é•œï¼ˆæ¯å¥/æ¯æ®µå¯¹åº”ä¸€å¼ å›¾ï¼‰ã€‚
 * ä¼˜å…ˆè°ƒç”¨è±†åŒ… APIï¼›å¤±è´¥æ—¶ç”¨æœ¬åœ°æŒ‰å¥åˆ‡åˆ†ã€‚
 */
const splitParagraphIntoScenes = async (paragraph: string, count: number, reasoningEffort: ReasoningEffort = 'minimal'): Promise<string[]> => {
  const trimmed = paragraph.trim();
  if (count <= 0) return [];
  if (count === 1) return [trimmed];

  const modelId = "doubao-seed-1-8-251228";
  const originalEndpoint = "https://ark.cn-beijing.volces.com/api/v3/chat/completions";
  const endpoint = getProxyUrl(originalEndpoint + "?_t=" + Date.now());

  const systemPrompt = `You are a video storyboard assistant. Split the user's paragraph into exactly ${count} scene descriptions for keyframes, in order. Each scene = one image for the video.
Output format: exactly ${count} lines. One scene per line. No numbering, no bullets, no extra explanation. Each line should be a short scene description (can be in Chinese or English).`;

  const userMessage = `Split this into exactly ${count} scenes (one per line):\n\n${trimmed}`;

  try {
    const controller = new AbortController();
    const timeoutId = setTimeout(() => controller.abort(), 20000);
    const response = await fetch(endpoint, {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        "Authorization": `Bearer ${getDoubaoApiKey()}`,
      },
      body: JSON.stringify({
        model: modelId,
        messages: [
          { role: "system", content: systemPrompt },
          { role: "user", content: userMessage },
        ],
        stream: false,
        temperature: 0.3,
        max_tokens: 800,
        reasoning_effort: reasoningEffort,
      }),
      signal: controller.signal,
    });
    clearTimeout(timeoutId);

    if (!response.ok) throw new Error(`Status ${response.status}`);
    const rawText = await response.text();
    const data = JSON.parse(rawText);
    const content = data.choices?.[0]?.message?.content;
    if (!content || typeof content !== "string") throw new Error("Empty response");

    const lines = content
      .split(/\n+/)
      .map((s: string) => s.replace(/^\s*[\d\.\-\*]+\s*/, "").trim())
      .filter((s: string) => s.length > 0);

    if (lines.length >= count) {
      return lines.slice(0, count);
    }
    if (lines.length > 0) {
      while (lines.length < count) lines.push(lines[lines.length - 1]);
      return lines.slice(0, count);
    }
  } catch (e) {
    console.warn("splitParagraphIntoScenes API failed, using local split:", e);
  }

  // æœ¬åœ°å›é€€ï¼šæŒ‰å¥å·ã€é—®å·ã€æ„Ÿå¹å·ã€æ¢è¡Œåˆ‡åˆ†ï¼Œå†å–å‰ N æ®µæˆ–å‡åŒ€åˆ†é…
  const sentences = trimmed
    .split(/[ã€‚ï¼ï¼Ÿ.!?\n]+/)
    .map(s => s.trim())
    .filter(s => s.length > 0);
  if (sentences.length === 0) return Array(count).fill(trimmed);

  const result: string[] = [];
  for (let i = 0; i < count; i++) {
    const idx = Math.floor((i * sentences.length) / count);
    result.push(sentences[Math.min(idx, sentences.length - 1)] || trimmed);
  }
  return result;
};

/**
 * Helper: Generate a SINGLE prompt via API
 * Optimized for Video Keyframes: Richer detail, cinematic terms.
 * sceneFocus = æœ¬å¼ å›¾å¯¹åº”çš„é‚£ä¸€æ®µè¯/é‚£ä¸€å¥ï¼Œåªæè¿°è¯¥åœºæ™¯ã€‚
 */
const generateSinglePromptWithDoubao = async (
  userInput: string,
  style: string,
  viewDistance: string,
  sceneFocus: string,
  index: number,
  totalCount: number,
  reasoningEffort: ReasoningEffort = 'minimal'
): Promise<string> => {
  const modelId = "doubao-seed-1-8-251228";
  const originalEndpoint = "https://ark.cn-beijing.volces.com/api/v3/chat/completions";
  const endpoint = getProxyUrl(originalEndpoint + (originalEndpoint.includes("?") ? "&" : "?") + "_t=" + (Date.now() + index));

  const sceneHint = totalCount > 1
    ? `\n    This is keyframe ${index + 1} of ${totalCount}. The image must depict ONLY this part of the story: "${sceneFocus}". Same world and style as the full story, but this frame's content is strictly this scene.`
    : "";

  const systemPrompt = `
    You are an expert Film Concept Artist.
    Task: Write ONE highly detailed, cinematic image generation prompt for a VIDEO keyframe.
    
    The full story/paragraph context: "${userInput}"
    This keyframe must show ONLY this scene (one part of the story): "${sceneFocus}"
    All keyframes together form one video, so keep the same world and style. AVOID simple or short descriptions.${sceneHint}
    
    Target Style: "${style}"
    Camera Distance: "${viewDistance}"
    
    Requirements:
    1. BE FAITHFUL to the source: describe exactly what the text says, no unrelated additions.
    2. Start with the main subject and action, then environment and background.
    3. Strictly enforce the "${style}" aesthetic and "${viewDistance}" composition.
    4. Add quality boosters: "8k", "cinematic lighting", "masterpiece".
    6. ERA & TIME PERIOD CONSISTENCY (critical for video): If the scene involves buildings, architecture, or people, choose ONE time period/era and describe ONLY that era. No anachronism. Keep clothing, architecture, and props all from the same era.
    7. NON-NARRATIVE = NO PEOPLE: If the text is informational, explanatory, or non-story (science, geography, nature, concepts), describe ONLY scenery/environment/objectsâ€”no people. Only include people when the text is narrative with characters or historical figures.
    8. CRITICAL: The image must contain NO text, no words, no letters, no writing, no captions, no subtitles, no signage with readable text. Describe only visual elements; never suggest any text or writing in the scene.
    9. Output ONLY the English prompt. No explanations. The prompt should be around 50-80 words.
  `;

  try {
    const controller = new AbortController();
    const timeoutId = setTimeout(() => controller.abort(), 30000);

    const response = await fetch(endpoint, {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        "Authorization": `Bearer ${getDoubaoApiKey()}`,
      },
      body: JSON.stringify({
        model: modelId,
        messages: [
          { role: "system", content: systemPrompt },
          { role: "user", content: "Generate cinematic prompt." }
        ],
        stream: false,
        temperature: 0.45,
        max_tokens: 400,
        reasoning_effort: reasoningEffort,
      }),
      signal: controller.signal
    });

    clearTimeout(timeoutId);

    if (!response.ok) {
      throw new Error(`Status ${response.status}`);
    }

    const rawText = await response.text();
    let content: string | undefined;

    try {
      const data = JSON.parse(rawText);
      content = data.choices?.[0]?.message?.content;
    } catch {
      // æ¥å£æœ‰æ—¶è¿”å›æˆªæ–­çš„ JSONï¼ˆUnterminated stringï¼‰ï¼Œå°è¯•ä»åŸæ–‡ä¸­æŠ½å– content
      const match = rawText.match(/"content"\s*:\s*"((?:[^"\\]|\\.)*)/);
      if (match) {
        content = match[1].replace(/\\(.)/g, "$1");
      }
    }

    if (!content || content.length < 20) throw new Error("Empty or invalid content");
    return content.trim();

  } catch (error) {
    const msg = error instanceof Error ? error.message : String(error);
    console.warn(`Doubao Prompt (Idx ${index}) failed (${msg}), using fallback.`);
    return ""; // ç©ºå­—ç¬¦ä¸²ä¼šè§¦å‘ fallback
  }
};

/** æœ¬åœ°æŒ‰å¥åˆ‡åˆ†ï¼Œç”¨äº sceneText å±•ç¤ºï¼ˆæ— éœ€ APIï¼‰ */
const localSplitScenes = (paragraph: string, count: number): string[] => {
  const trimmed = paragraph.trim();
  if (count <= 0) return [];
  if (count === 1) return [trimmed];
  const sentences = trimmed
    .split(/[ã€‚ï¼ï¼Ÿ.!?\n]+/)
    .map((s) => s.trim())
    .filter((s) => s.length > 0);
  if (sentences.length === 0) return Array(count).fill(trimmed);
  const result: string[] = [];
  for (let i = 0; i < count; i++) {
    const idx = Math.floor((i * sentences.length) / count);
    result.push(sentences[Math.min(idx, sentences.length - 1)] || trimmed);
  }
  return result;
};

/**
 * ä¸€æ¬¡ API è°ƒç”¨ï¼Œç›´æ¥è¿”å› N æ¡å›¾ç‰‡ promptã€‚
 * è¾“å‡ºæ ¼å¼ï¼šN è¡Œï¼Œæ¯è¡Œä¸€æ¡è‹±æ–‡ promptï¼Œå‡å°‘ token æå‡é€Ÿåº¦ã€‚
 */
const generatePromptsInOneCall = async (
  userInput: string,
  style: string,
  count: number,
  viewDistance: string,
  reasoningEffort: ReasoningEffort = 'minimal'
): Promise<{ prompt: string; sceneText: string }[]> => {
  const modelId = "doubao-seed-1-8-251228";
  const originalEndpoint = "https://ark.cn-beijing.volces.com/api/v3/chat/completions";
  const endpoint = getProxyUrl(originalEndpoint + "?_t=" + Date.now());

  const systemPrompt = `You are a Film Concept Artist. Output exactly ${count} English image prompts for a video, one per line.

CRITICAL - COVER ALL EXAMPLES: If the text mentions multiple distinct people or examples (e.g., Lincoln AND Helen Keller), you MUST depict each in at least one keyframe. Do NOT omit any named person or major example. Distribute keyframes across the full narrative.

CRITICAL - NON-NARRATIVE = NO PEOPLE: If the text is informational, explanatory, or non-story (e.g., science, geography, nature, concepts, how-things-work), describe ONLY scenery, environment, objects, or abstract visuals. Do NOT include any people, characters, or human figures.

Rules: Faithful to the source. Style: "${style}". Camera: "${viewDistance}". Add "8k, cinematic lighting, masterpiece". No text in images. Same world/era where relevant. Each prompt 50-80 words.
Output: exactly ${count} lines, one prompt per line, no numbering.`;

  const userMessage = `Generate ${count} keyframe prompts for:\n\n${userInput.trim()}`;

  try {
    const controller = new AbortController();
    const timeoutId = setTimeout(() => controller.abort(), 30000);
    const response = await fetch(endpoint, {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        "Authorization": `Bearer ${getDoubaoApiKey()}`,
      },
      body: JSON.stringify({
        model: modelId,
        messages: [
          { role: "system", content: systemPrompt },
          { role: "user", content: userMessage },
        ],
        stream: false,
        temperature: 0.45,
        max_tokens: 1200,
        reasoning_effort: reasoningEffort,
      }),
      signal: controller.signal,
    });
    clearTimeout(timeoutId);

    if (!response.ok) throw new Error(`Status ${response.status}`);
    const rawText = await response.text();
    const data = JSON.parse(rawText);
    const content = data.choices?.[0]?.message?.content;
    if (!content || typeof content !== "string") throw new Error("Empty response");

    const lines = content
      .split(/\n+/)
      .map((s: string) => s.replace(/^\s*[\d\.\-\*]+\s*/, "").trim())
      .filter((s: string) => s.length > 20);

    const sceneTexts = localSplitScenes(userInput, count);
    const results: { prompt: string; sceneText: string }[] = [];
    for (let i = 0; i < count; i++) {
      const prompt = lines[i]?.trim() || "";
      if (prompt.length > 20) {
        results.push({ prompt, sceneText: sceneTexts[i] ?? "" });
      }
    }

    if (results.length >= count) return results.slice(0, count);
    if (results.length > 0) {
      const last = results[results.length - 1];
      while (results.length < count) results.push({ ...last });
      return results.slice(0, count);
    }
  } catch (e) {
    console.warn("generatePromptsInOneCall failed, fallback to parallel:", e);
  }

  return [];
};

/**
 * å›é€€ï¼šæŒ‰åœºæ™¯åˆ‡åˆ† + å¹¶è¡Œç”Ÿæˆ promptï¼ˆåŸé€»è¾‘ï¼‰ï¼Œè¿”å›å¸¦ sceneText çš„ç»“æœã€‚
 */
const generatePromptsParallel = async (
  userInput: string,
  style: string,
  count: number,
  viewDistance: string,
  reasoningEffort: ReasoningEffort = 'minimal'
): Promise<{ prompt: string; sceneText: string }[]> => {
  const scenes = await splitParagraphIntoScenes(userInput, count, reasoningEffort);
  const fallbackSuffixes = [
    "dramatic cinematic lighting, same era",
    "intricate details, 8k resolution, coherent era",
    "dynamic angle, depth of field, same era",
    "vibrant colors, color graded, single era",
    "detailed background, environmental storytelling, same era",
    "artistic interpretation, masterpiece, era consistent",
  ];

  const promises = Array.from({ length: count }).map(async (_, i) => {
    const sceneFocus = scenes[i] ?? userInput;
    let prompt: string;

    try {
      const apiResult = await generateSinglePromptWithDoubao(userInput, style, viewDistance, sceneFocus, i, count, reasoningEffort);
      if (apiResult && apiResult.length > 20) {
        prompt = apiResult;
      } else {
        prompt = generateFallbackPrompt(userInput, style, viewDistance, fallbackSuffixes[i % fallbackSuffixes.length], sceneFocus);
      }
    } catch (err) {
      console.warn(`Prompt ${i} API call error:`, err);
      prompt = generateFallbackPrompt(userInput, style, viewDistance, fallbackSuffixes[i % fallbackSuffixes.length], sceneFocus);
    }

    return { prompt, sceneText: sceneFocus };
  });

  return Promise.all(promises);
};

/**
 * Generates detailed image prompts. ä¼˜å…ˆä¸€æ¬¡è°ƒç”¨ï¼ˆæ›´å¿«ï¼‰ï¼Œå¤±è´¥æ—¶å›é€€åˆ°å¹¶è¡Œã€‚
 */
export const generateCreativePrompts = async (
  userInput: string,
  style: string,
  count: number = 4,
  viewDistance: string = 'Default',
  reasoningEffort: ReasoningEffort = 'minimal'
): Promise<{ prompt: string; sceneText: string }[]> => {
  const oneCall = await generatePromptsInOneCall(userInput, style, count, viewDistance, reasoningEffort);
  if (oneCall.length >= count) return oneCall;
  return generatePromptsParallel(userInput, style, count, viewDistance, reasoningEffort);
};

let lastImageGenDebugSnippet = "";
/** å›¾ç‰‡ç”Ÿæˆå¤±è´¥æ—¶æœ€è¿‘ä¸€æ¬¡æ¥å£å“åº”/é”™è¯¯ç‰‡æ®µï¼Œä¾¿äºå¤åˆ¶æ’æŸ¥ */
export function getLastImageGenDebugInfo(): string {
  return lastImageGenDebugSnippet;
}

/** Volces/TOS ç­¾åå›¾ URL æ˜¯å¦å®Œæ•´ï¼ˆæˆªæ–­çš„ URL ä¼šå¯¼è‡´å›¾ç‰‡åŠ è½½å¤±è´¥ï¼Œå¦‚æœ«å°¾ x-tos-process=image_YXï¼‰ */
function isVolcesImageUrlComplete(url: string): boolean {
  if (!url || !url.startsWith("http")) {
    console.warn(`[URL Check] Invalid URL format: ${url?.slice(0, 50)}`);
    return false;
  }
  
  // é Volces/TOS URL ç›´æ¥é€šè¿‡
  if (!/volces\.com|tos-cn-beijing/i.test(url)) {
    console.log(`[URL Check] Non-Volces URL, accepted: ${url.slice(0, 80)}`);
    return true;
  }
  
  // å¿…é¡»æœ‰å®Œæ•´ç­¾åï¼šX-Tos-Signature=<64ä½åå…­è¿›åˆ¶>
  const signatureMatch = url.match(/X-Tos-Signature=([0-9a-f]+)/i);
  if (!signatureMatch) {
    console.warn(`[URL Check] Missing X-Tos-Signature in Volces URL`);
    return false;
  }
  if (signatureMatch[1].length !== 64) {
    console.warn(`[URL Check] Incomplete signature: ${signatureMatch[1].length}/64 chars`);
    return false;
  }
  
  // æ£€æŸ¥ URL æ˜¯å¦çªç„¶æˆªæ–­ï¼ˆä¸ä»¥æ­£å¸¸å­—ç¬¦ç»“å°¾ï¼‰
  const lastChar = url.slice(-1);
  const validEndings = /[a-zA-Z0-9=\-_]/;
  if (!validEndings.test(lastChar)) {
    console.warn(`[URL Check] URL ends with suspicious char: '${lastChar}'`);
    return false;
  }
  
  // è‹¥å« x-tos-process=ï¼Œæœ«å°¾å‚æ•°å€¼éœ€è¶³å¤Ÿé•¿ï¼ˆå®Œæ•´ä¸º image/watermark,image_<base64>ï¼Œæˆªæ–­å¸¸ä¸º image_YXï¼‰
  const processMatch = url.match(/x-tos-process=([^&]*)$/i);
  if (processMatch) {
    try {
      const value = decodeURIComponent(processMatch[1] || "");
      if (value.length < 40) {
        console.warn(`[URL Check] x-tos-process value too short: ${value.length} chars (${value.slice(0, 30)})`);
        return false;
      }
    } catch (e) {
      console.warn(`[URL Check] Failed to decode x-tos-process: ${processMatch[1]?.slice(0, 30)}`);
      return false;
    }
  }
  
  console.log(`[URL Check] âœ“ Complete Volces URL validated (${url.length} chars)`);
  return true;
}

/**
 * å›¾ç‰‡ç”Ÿæˆï¼šè±†åŒ… Seedreamï¼ˆOpenAI å…¼å®¹æ¥å£ï¼‰
 * base_url: https://ark.cn-beijing.volces.com/api/v3
 * å®˜æ–¹æ¡ˆä¾‹ï¼šclient.images.generate(model="doubao-seedream-4-5-251128", prompt=..., size="2K", response_format="url", extra_body={"watermark": True})
 */
/** imageIndex: å¤šå›¾æ—¶ä¼ å…¥ 0-based åºå·ï¼Œç”¨äºä¸åŒ seed æå‡ç”»é¢å·®å¼‚åº¦ */
export const generateImageFromPrompt = async (
  prompt: string,
  aspectRatio: string = "1:1",
  imageIndex?: number
): Promise<string> => {
  lastImageGenDebugSnippet = "";
  const originalEndpoint = "https://ark.cn-beijing.volces.com/api/v3/images/generations";

  const apiKey = getDoubaoApiKey();
  if (!apiKey) {
    lastImageGenDebugSnippet = "æœªé…ç½® VITE_DOUBAO_API_KEY";
    throw new Error(
      "æœªé…ç½®å›¾åƒç”Ÿæˆ Keyã€‚è¯·åœ¨ .env ä¸­è®¾ç½® VITE_DOUBAO_API_KEYï¼ˆç«å±±æ–¹èˆŸæ§åˆ¶å°è·å–ï¼Œéœ€å¼€é€š Seedream å›¾åƒç”Ÿæˆï¼‰ï¼Œä¿å­˜åé‡å¯ devã€‚"
    );
  }

  // ä¸å®˜æ–¹ OpenAI å…¼å®¹æ¥å£ä¸€è‡´ï¼šsize "2K"ï¼Œresponse_format "url"ï¼Œwatermark å¯é€‰
  const sizeMap: Record<string, string> = {
    "1:1": "2K",
    "16:9": "2K",
    "4:3": "2K",
    "3:4": "2K",
    "9:16": "2K",
  };
  const size = sizeMap[aspectRatio] ?? "2K";

  // å¤šå›¾æ—¶æ¯å¼ ç”¨ä¸åŒ seedï¼Œé™ä½ç›¸ä¼¼åº¦ï¼›å•å¼ æˆ–ä¸ä¼ æ—¶ç”¨ -1 éšæœº
  const seed = imageIndex !== undefined ? 10000 + imageIndex : -1;

  const body = JSON.stringify({
    model: "doubao-seedream-4-5-251128",
    prompt: `${prompt.trim()} No text, no words, no letters, no writing, no captions in the image.`,
    size,
    response_format: "url",
    watermark: false,
    seed,
  });
  const headers = {
    "Content-Type": "application/json",
    "Authorization": `Bearer ${apiKey}`,
  };

  const tryFetch = async (endpoint: string): Promise<Response> => {
    const controller = new AbortController();
    const timeoutId = setTimeout(() => controller.abort(), 120000);
    const response = await fetch(endpoint, { method: "POST", headers, body, signal: controller.signal });
    clearTimeout(timeoutId);
    return response;
  };

  let lastErr: string = "";
  let isAuthError = false;
  
  for (let attempt = 0; attempt < 3; attempt++) {
    const endpoints = [getProxyUrl(originalEndpoint)];
    const fallback = getFallbackCorsProxy();
    if (fallback) endpoints.push(fallback + encodeURIComponent(originalEndpoint));
    
    if (attempt > 0) {
      // æŒ‡æ•°é€€é¿ï¼šç¬¬1æ¬¡é‡è¯•ç­‰3ç§’ï¼Œç¬¬2æ¬¡é‡è¯•ç­‰6ç§’
      const delay = 3000 * attempt;
      console.log(`[Image Gen] Retry ${attempt}/3 after ${delay}ms...`);
      await new Promise(r => setTimeout(r, delay));
    }
    
    for (const endpoint of endpoints) {
      try {
        console.log(`[Image Gen] Attempt ${attempt + 1}/3, endpoint: ${endpoint.slice(0, 60)}...`);
        const response = await tryFetch(endpoint);
        
        // Use arrayBuffer + TextDecoder for more reliable reading
        const buffer = await response.arrayBuffer();
        const responseText = new TextDecoder('utf-8').decode(buffer);
        
        console.log(`[Image Gen] Response: ${response.status}, length: ${responseText.length} chars (${buffer.byteLength} bytes)`);
        
        if (!response.ok) {
          lastErr = `HTTP ${response.status}: ${responseText.slice(0, 300)}`;
          lastImageGenDebugSnippet = `[Image ${response.status}]\n${responseText.slice(0, 800)}`;
          
          // æ£€æŸ¥æ˜¯å¦æ˜¯è®¤è¯é”™è¯¯ï¼ˆä¸å€¼å¾—é‡è¯•ï¼‰
          if (response.status === 401 || response.status === 403) {
            isAuthError = true;
            throw new Error(lastErr);
          }
          
          // æ£€æŸ¥æ˜¯å¦æ˜¯é…é¢/é™æµé”™è¯¯
          if (response.status === 429 || responseText.includes("quota") || responseText.includes("rate limit")) {
            lastErr += " (API é…é¢ä¸è¶³æˆ–é™æµ)";
            throw new Error(lastErr);
          }
          
          throw new Error(lastErr);
        }
        let data: { data?: Array<{ url?: string }>; error?: { message?: string } } | null = null;
        try {
          data = JSON.parse(responseText);
        } catch (parseErr) {
          // å“åº”å¯èƒ½è¢«æˆªæ–­æˆ–å«ç‰¹æ®Šå­—ç¬¦ï¼Œå°è¯•ä»æ­£æ–‡ä¸­æå– data[0].url
          console.warn(`JSON parse failed (${responseText.length} chars), attempting URL extraction:`, parseErr);
          
          // å°è¯•å¤šç§æ–¹å¼æå– URL
          let extractedUrl: string | undefined;
          
          // æ–¹æ³•1: æ­£åˆ™åŒ¹é… "url": "https://..."
          const match1 = responseText.match(/"url"\s*:\s*"(https?:\/\/[^"\\]+(?:\\.[^"\\]*)*)"/);
          if (match1) {
            extractedUrl = match1[1].replace(/\\(.)/g, "$1"); // å¤„ç†è½¬ä¹‰å­—ç¬¦
          }
          
          // æ–¹æ³•2: æŸ¥æ‰¾ Volces/TOS URLï¼ˆåŒ…å«ç­¾åï¼‰
          if (!extractedUrl) {
            const volcesMatch = responseText.match(/(https?:\/\/[^"\s]+?(?:volces\.com|tos-cn-beijing)[^"\s]*X-Tos-Signature=[0-9a-f]{64}[^"\s]*)/i);
            if (volcesMatch) {
              extractedUrl = volcesMatch[1].split('"')[0].split('\\')[0];
            }
          }
          
          // æ–¹æ³•3: é€šç”¨ HTTPS URL æå–
          if (!extractedUrl && responseText.includes("https://")) {
            const urlStart = responseText.indexOf("https://");
            const after = responseText.slice(urlStart);
            const end = after.search(/["'\s\\]/);
            extractedUrl = end !== -1 ? after.slice(0, end) : after.trim();
          }
          
          console.log(`Extracted URL candidate: ${extractedUrl?.slice(0, 100)}...`);
          
          if (extractedUrl && isVolcesImageUrlComplete(extractedUrl)) {
            console.log(`âœ“ Successfully extracted complete URL from truncated JSON`);
            return extractedUrl;
          }
          
          lastErr = `æ¥å£è¿”å›äº†è¢«æˆªæ–­çš„ JSONï¼ˆæ”¶åˆ° ${responseText.length} å­—ç¬¦ï¼‰ã€‚${extractedUrl ? 'æå–åˆ°çš„ URL ä¸å®Œæ•´ã€‚' : 'æœªèƒ½æå–åˆ°æœ‰æ•ˆ URLã€‚'}å¯èƒ½åŸå› ï¼šç½‘ç»œä¸ç¨³å®šã€ä»£ç†æœåŠ¡é—®é¢˜ã€æˆ–ç«å±±å¼•æ“ API å“åº”å¼‚å¸¸ã€‚`;
          lastImageGenDebugSnippet = `å“åº”é•¿åº¦: ${responseText.length} å­—ç¬¦\næå–çš„URL: ${extractedUrl?.slice(0, 200) || 'æ— '}\n\nå“åº”å‰ 800 å­—ç¬¦:\n${responseText.slice(0, 800)}\n\nå“åº”å 200 å­—ç¬¦:\n${responseText.slice(-200)}`;
          throw new Error(lastErr);
        }
        if (data?.data?.[0]?.url) {
          const originalUrl = data.data[0].url;
          if (!isVolcesImageUrlComplete(originalUrl)) {
            lastErr = "æ¥å£è¿”å›çš„å›¾ç‰‡ URL ä¸å®Œæ•´ï¼ˆå¯èƒ½è¢«æˆªæ–­ï¼‰";
            lastImageGenDebugSnippet = originalUrl?.slice(0, 500) ?? "";
            throw new Error(lastErr);
          }
          // ç›´æ¥è¿”å› Volces ç­¾åé“¾æ¥ï¼Œé¿å… /api/proxy è¢«å¹¿å‘Šæ‹¦æˆªå™¨æ‹¦æˆªï¼ˆERR_BLOCKED_BY_CLIENTï¼‰
          return originalUrl;
        }
        const apiMsg = data?.error?.message ?? (data as any)?.message ?? "";
        lastErr = apiMsg ? `æ¥å£è¿”å›æ— å›¾ç‰‡: ${apiMsg}` : "æ¥å£è¿”å›æ—  data[0].url";
        lastImageGenDebugSnippet = responseText.slice(0, 800);
        throw new Error(lastErr);
      } catch (err) {
        const msg = err instanceof Error ? err.message : String(err);
        if (!lastErr) lastErr = msg;
        console.warn(`[Image Gen] Attempt failed on ${endpoint.slice(0, 50)}:`, msg);
        
        // å¦‚æœæ˜¯è®¤è¯é”™è¯¯ï¼Œä¸è¦ç»§ç»­å°è¯•å…¶ä»– endpoint
        if (isAuthError) break;
        continue;
      }
    }
    
    // å¦‚æœæ˜¯è®¤è¯é”™è¯¯ï¼Œä¸è¦é‡è¯•
    if (isAuthError) break;
  }
  
  // æ„å»ºè¯¦ç»†çš„é”™è¯¯æç¤º
  let hint = "è¯·æ£€æŸ¥ï¼š\n";
  if (isAuthError) {
    hint += "âŒ API Key æ— æ•ˆæˆ–æœªæˆæƒã€‚è¯·ç¡®è®¤ï¼š\n";
    hint += "1) .env ä¸­çš„ VITE_DOUBAO_API_KEY æ­£ç¡®ï¼ˆä»ç«å±±å¼•æ“æ§åˆ¶å°è·å–ï¼‰\n";
    hint += "2) è¯¥ Key å·²åœ¨ç«å±±å¼•æ“æ§åˆ¶å°å¼€é€šã€Œå›¾åƒç”Ÿæˆã€/ Seedream æ¨¡å‹æƒé™\n";
    hint += "3) Key æœªè¿‡æœŸä¸”æœ‰è¶³å¤Ÿé…é¢";
  } else if (lastErr.includes("é…é¢") || lastErr.includes("quota") || lastErr.includes("rate limit")) {
    hint += "âš ï¸ API é…é¢ä¸è¶³æˆ–è§¦å‘é™æµã€‚è¯·æ£€æŸ¥ï¼š\n";
    hint += "1) ç«å±±å¼•æ“æ§åˆ¶å°ä½™é¢æ˜¯å¦å……è¶³\n";
    hint += "2) æ˜¯å¦è§¦å‘äº†æ¯æ—¥/æ¯åˆ†é’Ÿè°ƒç”¨é™åˆ¶\n";
    hint += "3) ç¨åå†è¯•";
  } else if (lastErr.includes("æˆªæ–­")) {
    hint += "âš ï¸ å“åº”æ•°æ®è¢«æˆªæ–­ï¼ˆå¯èƒ½åŸå› ï¼‰ï¼š\n";
    hint += "1) ç½‘ç»œä¸ç¨³å®šå¯¼è‡´ä¼ è¾“ä¸­æ–­ï¼ˆè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥ï¼‰\n";
    hint += "2) ä»£ç†æœåŠ¡å™¨é…ç½®é—®é¢˜ï¼ˆå¦‚ä½¿ç”¨ corsproxy.io å¯èƒ½ä¸ç¨³å®šï¼‰\n";
    hint += "3) æœ¬åœ°å¼€å‘æœåŠ¡å™¨è¶…æ—¶ï¼ˆé‡å¯ npm run devï¼‰\n";
    hint += "4) ç«å±±å¼•æ“ API å“åº”å¼‚å¸¸ï¼ˆç¨åé‡è¯•ï¼‰\n";
    hint += "\nğŸ’¡ å»ºè®®ï¼šä½¿ç”¨ npm start è‡ªå»ºä»£ç†æœåŠ¡å™¨ï¼Œæˆ–éƒ¨ç½²åˆ° Vercel";
  } else {
    hint += "1) æœ¬é¡µä¸å¼€å‘æœåŠ¡åŒæºï¼ˆå¦‚ localhost:3000ï¼‰ï¼Œ/api/proxy å¯ç”¨\n";
    hint += "2) ç«å±±å¼•æ“æ§åˆ¶å°è¯¥ Key å·²å¼€é€šã€Œå›¾åƒç”Ÿæˆã€/ Seedream æ¨¡å‹\n";
    hint += "3) å¢ƒå†…è®¿é—®å¢ƒå¤–ç«™ç‚¹æ—¶éœ€ä»£ç†æˆ–éƒ¨ç½²åˆ°å¢ƒå†…\n";
    hint += "4) æ£€æŸ¥æ§åˆ¶å°ï¼ˆF12ï¼‰æ˜¯å¦æœ‰ç½‘ç»œé”™è¯¯";
  }
  
  lastImageGenDebugSnippet = lastErr ? `æœ€åé”™è¯¯: ${lastErr}\n\nè°ƒè¯•ä¿¡æ¯:\n${lastImageGenDebugSnippet}` : "";
  throw new Error(`å›¾ç‰‡ç”Ÿæˆå¤±è´¥ã€‚\n\n${hint}${lastErr ? "\n\næœ€åé”™è¯¯: " + lastErr : ""}`);
};

export { generateSpeechDoubao } from './doubaoTtsService';
import type { DoubaoEmotionOptions } from './doubaoTtsService';

/**
 * è¯­éŸ³åˆæˆå…¥å£ï¼šä»…ä½¿ç”¨è±†åŒ… TTSï¼Œè¿”å› 24kHz PCM Int16 ArrayBufferã€‚
 * å¯é€‰ options.emotion / options.emotionScale è°ƒèŠ‚æœ—è¯»æƒ…æ„Ÿï¼ˆ2.0 é€šç”¨åœºæ™¯éŸ³è‰²æ”¯æŒï¼‰ã€‚
 */
export const generateSpeech = async (
  text: string,
  speaker: string,
  options?: DoubaoEmotionOptions
): Promise<ArrayBuffer> => {
  const { generateSpeechDoubao } = await import('./doubaoTtsService');
  return generateSpeechDoubao(text, speaker, options);
};